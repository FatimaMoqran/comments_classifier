{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WAIT = 10\n",
    "MAX_RETRY = 10\n",
    "MAX_SCROLLS = 40\n",
    "HEADER = ['id_review', 'review', 'retrieval_date', 'relative_date', 'rating', 'username', 'adress']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleMaps:\n",
    "\n",
    "    def __init__(self, csv):\n",
    "        folder = \"data/\"\n",
    "        file = \"all_reviews_orange.csv\"\n",
    "        self.targetfile = open(folder + file, mode='w', encoding='utf-8', newline='\\n')\n",
    "        \n",
    "        self.df = pd.read_csv(csv, sep = ';')\n",
    "        \n",
    "        self.writer = self.__get_writer(HEADER)\n",
    "        self.driver = self.__get_driver()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, tb):\n",
    "        print('Closing chromedriver...')\n",
    "        self.driver.close()\n",
    "        self.driver.quit()\n",
    "        self.targetfile.close()\n",
    "    \n",
    "    def __get_writer(self, header):\n",
    "        writer = csv.writer(self.targetfile, quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow(header)\n",
    "        return writer\n",
    "    \n",
    "    def __get_driver(self, debug=True):\n",
    "        options = Options()\n",
    "        if not debug:\n",
    "            options.add_argument(\"--headless\")\n",
    "        options.add_argument(\"--window-size=1366,768\")\n",
    "        options.add_argument(\"--disable-notifications\")\n",
    "        options.add_argument(\"--lang=en\")\n",
    "        input_driver = webdriver.Chrome(options=options)\n",
    "        return input_driver\n",
    "    \n",
    "    def get_reviews(self, all_reviews = True):\n",
    "        \n",
    "        # iteration over urls\n",
    "        for i in range(len(self.df.urls)):\n",
    "            self.adress = self.df.adress[i]\n",
    "            url = self.df.urls[i]\n",
    "            \n",
    "            self.driver.get(url)\n",
    "            wait = WebDriverWait(self.driver, MAX_WAIT)\n",
    "\n",
    "            # order reviews by date\n",
    "            menu_bt = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'div.goog-inline-block.section-dropdown-menu-button-caption')))\n",
    "\n",
    "            # get number of reviews\n",
    "            if all_reviews:\n",
    "                soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "                number_of_reviews = soup.find(\"div\", {\"class\":\"gm2-caption\"})\n",
    "                N = int(re.sub(\"\\D\", \"\",number_of_reviews.string))\n",
    "\n",
    "            # sometimes problem in loading the event on this button\n",
    "            clicked = False\n",
    "            tries = 0\n",
    "            while not clicked and tries < MAX_RETRY:\n",
    "                try:\n",
    "                    menu_bt.click()\n",
    "                    # second element of the list: most recent\n",
    "                    recent_rating_bt = self.driver.find_elements_by_xpath('//div[@role=\\'option\\']')[2]\n",
    "                    recent_rating_bt.click()\n",
    "\n",
    "                    clicked = True\n",
    "\n",
    "                    # wait to load review (ajax call)\n",
    "                    time.sleep(5)\n",
    "\n",
    "                except:\n",
    "                    tries += 1\n",
    "                    print('Warning: failed to click recent button')\n",
    "\n",
    "            # failed to change the filter\n",
    "            if tries == MAX_RETRY:\n",
    "                return -1\n",
    "\n",
    "\n",
    "            n_reviews_loaded = len(self.driver.find_elements_by_xpath('//div[@class=\\'section-review-content\\']'))\n",
    "            n_scrolls = 0\n",
    "            while n_reviews_loaded < N and n_scrolls < MAX_SCROLLS:\n",
    "\n",
    "                # scroll to load more reviews\n",
    "                scrollable_div = self.driver.find_element_by_css_selector(\n",
    "                    'div.section-layout.section-scrollbox.scrollable-y.scrollable-show')\n",
    "                self.driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "\n",
    "                # wait for other reviews to load (ajax)\n",
    "                time.sleep(4)\n",
    "\n",
    "                # expand review text\n",
    "                self.__expand_reviews()\n",
    "\n",
    "                n_reviews_loaded = len(self.driver.find_elements_by_xpath('//div[@class=\\'section-review-content\\']'))\n",
    "\n",
    "                n_scrolls += 1\n",
    "\n",
    "            response = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            reviews = response.find_all('div', class_='section-review-content')\n",
    "            \n",
    "            n_reviews = 0\n",
    "            for idx, review in enumerate(reviews):\n",
    "                n_reviews += self.__parse_reviews(review)\n",
    "            \n",
    "            print('Scraped reviews: ', n_reviews)\n",
    "            \n",
    "\n",
    "    def __parse_reviews(self, review):\n",
    "\n",
    "        item = {}\n",
    "\n",
    "        id_review = review.find('button', class_='section-review-action-menu')['data-review-id']\n",
    "        username = review.find('div', class_='section-review-title').find('span').text\n",
    "\n",
    "        try:\n",
    "            review_text = self.__filter_string(review.find('span', class_='section-review-text').text)\n",
    "        except:\n",
    "            review_text = None\n",
    "\n",
    "        rating = review.find('span', class_='section-review-stars')['aria-label'].split(' ')[1]\n",
    "        relative_date = review.find('span', class_='section-review-publish-date').text\n",
    "\n",
    "        item['id_review'] = id_review\n",
    "        item['review'] = review_text\n",
    "\n",
    "        # depends on language, which depends on geolocation defined by Google Maps\n",
    "        item['relative_date'] = relative_date\n",
    "\n",
    "        # store datetime of scraping and apply further processing to calculate\n",
    "        # correct date as retrieval_date - time(relative_date)\n",
    "        item['retrieval_date'] = datetime.now()\n",
    "        item['rating'] = rating\n",
    "        item['username'] = username\n",
    "        item['adress'] = self.adress\n",
    "        \n",
    "        self.writer.writerow(list(item.values()))\n",
    "\n",
    "        return 1\n",
    "    \n",
    "    # expand review description\n",
    "    def __expand_reviews(self):\n",
    "        # use XPath to load complete reviews\n",
    "        links = self.driver.find_elements_by_xpath('//button[contains(@class, \"section-expand-review blue-link\")]')\n",
    "        for l in links:\n",
    "            l.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # util function to clean special characters\n",
    "    def __filter_string(self, str):\n",
    "        strOut = str.replace('\\r', ' ').replace('\\n', ' ').replace('\\t', ' ')\n",
    "        \n",
    "        return strOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped reviews:  410\n",
      "Scraped reviews:  159\n",
      "Scraped reviews:  140\n",
      "Scraped reviews:  0\n",
      "Scraped reviews:  149\n",
      "Scraped reviews:  91\n",
      "Scraped reviews:  100\n",
      "Scraped reviews:  101\n",
      "Scraped reviews:  139\n",
      "Scraped reviews:  197\n",
      "Scraped reviews:  100\n",
      "Scraped reviews:  287\n",
      "Scraped reviews:  307\n",
      "Scraped reviews:  46\n",
      "Scraped reviews:  106\n",
      "Scraped reviews:  188\n",
      "Scraped reviews:  120\n",
      "Scraped reviews:  140\n",
      "Scraped reviews:  30\n",
      "Scraped reviews:  140\n",
      "Closing chromedriver...\n"
     ]
    }
   ],
   "source": [
    "with GoogleMaps('urls_boutiques_orange.csv') as scraper:\n",
    "    scraper.get_reviews()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
